{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5174e+00,  3.5516e-01,  1.0483e+00, -5.3858e-05, -1.5182e-02,\n",
      "         -2.2228e-03, -3.1634e-03, -1.4061e-02, -1.7340e-02,  1.3951e-01,\n",
      "          9.2359e-01,  8.2124e-01,  1.3044e+00, -9.7913e-03, -8.5220e-03,\n",
      "         -1.7867e-03,  1.8585e+00,  1.0275e+00, -2.8374e-02, -1.6976e-02,\n",
      "         -6.1185e-03,  1.8987e-01,  1.6319e-01,  1.4393e+00,  1.0598e+00,\n",
      "         -4.8188e-03,  7.7611e-01,  1.4606e-01,  1.7014e+00, -2.1494e-03,\n",
      "         -7.8358e-03,  3.1321e-01, -7.5873e-03, -3.4291e-03, -3.2107e-02,\n",
      "         -1.1904e-02,  2.6295e-01,  1.8799e+00,  1.8189e-01, -3.5094e-03,\n",
      "          1.1845e-01,  7.7927e-01, -6.8809e-03,  3.2673e-01, -2.7036e-02,\n",
      "          8.1007e-02, -1.4422e-02,  8.2568e-01, -3.5537e-03,  1.7976e+00,\n",
      "         -1.3333e-02,  1.3015e+00, -5.9352e-03,  1.2685e+00, -1.5115e-02,\n",
      "          3.6978e-01, -7.3173e-03, -8.2925e-03,  1.0169e+00, -7.5506e-04,\n",
      "          6.0862e-01,  2.2670e+00, -1.2531e-02,  3.2300e-01,  1.3163e+00,\n",
      "          1.2173e+00, -1.6651e-02,  1.0695e+00, -1.6606e-02, -1.7528e-03,\n",
      "         -6.5975e-03, -9.5603e-03,  9.4515e-01,  4.3776e-01, -1.1667e-02,\n",
      "          2.4579e-01,  1.7343e+00, -5.0546e-03, -5.1263e-03,  5.7065e-02,\n",
      "          2.9442e-01, -1.2681e-02,  1.1069e+00,  4.4597e-01, -2.3361e-02,\n",
      "          4.6515e-01, -1.6582e-02,  1.8484e-02,  7.6987e-01, -1.2124e-02,\n",
      "          1.0298e+00,  1.5358e+00, -1.4431e-02, -8.2650e-03, -1.2798e-02,\n",
      "         -1.2919e-02, -2.6041e-02,  1.8720e+00,  4.1504e-01, -1.6262e-02,\n",
      "         -1.1142e-02,  2.2481e-01,  9.4809e-01,  1.8886e+00,  1.4471e+00,\n",
      "         -7.7892e-03, -1.3921e-02, -2.4957e-02, -3.7648e-02,  6.8053e-01,\n",
      "         -2.2130e-02, -1.0589e-02, -5.8879e-03,  4.1021e-01,  7.3520e-01,\n",
      "          7.1019e-01,  1.7165e+00, -8.4524e-03, -8.8539e-05, -7.6584e-03,\n",
      "         -6.2622e-03, -1.5288e-03,  1.6627e+00, -4.9281e-03, -1.1204e-03,\n",
      "          1.8227e-01, -2.6728e-02,  6.6592e-01]], grad_fn=<LeakyReluBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "input_shape = (5, 128, 128, 128)  # 5 channels, 128x128x128 spatial dimensions\n",
    "network_depth = 4\n",
    "no_convolutions = 2\n",
    "conv_filter_no_init = 32\n",
    "conv_kernel_size = 3\n",
    "latent_representation_dim = 128\n",
    "l1 = 0.01\n",
    "l2 = 0.01\n",
    "dropout_value = 0.5\n",
    "use_batch_normalization = True\n",
    "activation = 'leakyrelu'\n",
    "\n",
    "# Instantiating the encoder\n",
    "encoder_model = encoder(\n",
    "    input_shape=input_shape,\n",
    "    network_depth=network_depth,\n",
    "    no_convolutions=no_convolutions,\n",
    "    conv_filter_no_init=conv_filter_no_init,\n",
    "    conv_kernel_size=conv_kernel_size,\n",
    "    latent_representation_dim=latent_representation_dim,\n",
    "    l1=l1,\n",
    "    l2=l2,\n",
    "    dropout_value=dropout_value,\n",
    "    use_batch_normalization=use_batch_normalization,\n",
    "    activation=activation,\n",
    "    gaussian_noise_factor = 0.3\n",
    ")\n",
    "\n",
    "# Generating random input data (Batch size 1, input shape as defined above)\n",
    "input_data = torch.randn(1, *input_shape)\n",
    "\n",
    "# Forward pass (calling forward without any keyword arguments)\n",
    "output = encoder_model(input_data)\n",
    "\n",
    "# Output the latent representation\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 3-0: in_channels = 128, out_channels = 128\n",
      "Layer 3-1: in_channels = 128, out_channels = 128\n",
      "Layer 2-0: in_channels = 128, out_channels = 64\n",
      "Layer 2-1: in_channels = 64, out_channels = 64\n",
      "Layer 1-0: in_channels = 64, out_channels = 32\n",
      "Layer 1-1: in_channels = 32, out_channels = 32\n",
      "Layer 0-0: in_channels = 32, out_channels = 16\n",
      "Layer 0-1: in_channels = 16, out_channels = 16\n",
      "Final Layer: in_channels = 16, out_channels = 5\n",
      "Reconstruction shape: torch.Size([1, 5, 64, 64, 64])\n",
      "Latent parameters: tensor([[ 0.0689, -0.1915]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Compile the model\n",
    "model, optimizer = compile_all_models(\n",
    "    input_shape=input_shape,\n",
    "    network_depth=network_depth,\n",
    "    no_convolutions=no_convolutions,\n",
    "    conv_filter_no_init=conv_filter_no_init,\n",
    "    conv_kernel_size=conv_kernel_size,\n",
    "    latent_representation_dim=latent_representation_dim,\n",
    "    dropout_value=dropout_value,\n",
    "    use_batch_normalization=use_batch_normalization,\n",
    "    activation=activation,\n",
    "    l1=l1,\n",
    "    l2=l2,\n",
    "    lr=lr\n",
    ")\n",
    "\n",
    "# Example input for forward pass\n",
    "input_data = torch.randn(1, *input_shape)  # Example input\n",
    "\n",
    "# Forward pass\n",
    "reconstruction, latent_params = model(input_data)\n",
    "print(\"Reconstruction shape:\", reconstruction.shape)\n",
    "print(\"Latent parameters:\", latent_params)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
