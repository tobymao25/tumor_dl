{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# # link to data \n",
    "# # https://www.kaggle.com/datasets/abdullahalmunem/brats17/data\n",
    "\n",
    "# # Define the base path and destination path\n",
    "# base_path = \"/Users/lindatang/Desktop/tumor_dl/BRATS2017/Brats17TrainingData/HGG\"\n",
    "# destination_path = \"/Users/lindatang/Desktop/tumor_dl/BRATS2017/TrainingDataset/images\"\n",
    "\n",
    "# # Ensure the destination directory exists\n",
    "# os.makedirs(destination_path, exist_ok=True)\n",
    "\n",
    "# # Loop through the subfolders in the base path\n",
    "# for patient_folder in os.listdir(base_path):\n",
    "#     patient_path = os.path.join(base_path, patient_folder)\n",
    "    \n",
    "#     # Check if it's a directory\n",
    "#     if os.path.isdir(patient_path):\n",
    "#         # Loop through the files in the patient folder\n",
    "#         for file_name in os.listdir(patient_path):\n",
    "#             if file_name.endswith(\"flair.nii\"):\n",
    "#                 # Construct full file path\n",
    "#                 file_path = os.path.join(patient_path, file_name)\n",
    "                \n",
    "#                 # Copy the file to the destination folder\n",
    "#                 shutil.copy(file_path, destination_path)\n",
    "#                 print(f\"Copied {file_name} to {destination_path}\")\n",
    "\n",
    "# print(\"Finished copying t1ce.nii files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchio as tio\n",
    "from img_branch_utils import GBMdataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define the directory with images and segmentation\n",
    "image_dir = \"/Users/lindatang/Desktop/tumor_dl/BRATS2017/TrainingDataset/images\"\n",
    "\n",
    "# Define the path to the CSV file containing the patient survival data\n",
    "csv_path = \"/Users/lindatang/Desktop/tumor_dl/BRATS2017/survival_data_small.csv\" # TODO-\n",
    "\n",
    "# Create the dataset\n",
    "dataset = GBMdataset(image_dir=image_dir, csv_path=csv_path)\n",
    "\n",
    "# Create the DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example loop over the data\n",
    "# for batch_idx, (images, survival_times) in enumerate(dataloader):\n",
    "#     if batch_idx < 2:  # Only print for the first 2 batches\n",
    "#         print(f\"Batch {batch_idx + 1}\")\n",
    "#         print(f\"Images shape: {images.shape}\")\n",
    "#         print(f\"Survival times: {survival_times}\")\n",
    "#     else:\n",
    "#         break  # Exit the loop after the first 2 batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNoise3D(nn.Module):\n",
    "    def __init__(self, mean=0.0, std=0.1):\n",
    "        super(GaussianNoise3D, self).__init__()\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.training:  # Apply noise only during training\n",
    "            noise = torch.randn_like(x) * self.std + self.mean\n",
    "            return x + noise\n",
    "        return x\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_shape, network_depth, no_convolutions, conv_filter_no_init, \n",
    "                 conv_kernel_size, latent_representation_dim, l1, l2, dropout_value, \n",
    "                 use_batch_normalization, activation, gaussian_noise_std=None):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.input_shape = input_shape\n",
    "        self.network_depth = network_depth\n",
    "        self.no_convolutions = no_convolutions\n",
    "        self.conv_filter_no_init = conv_filter_no_init\n",
    "        self.conv_kernel_size = conv_kernel_size\n",
    "        self.latent_representation_dim = latent_representation_dim\n",
    "        self.l1 = l1\n",
    "        self.l2 = l2\n",
    "        self.dropout_value = dropout_value\n",
    "        self.use_batch_normalization = use_batch_normalization\n",
    "        self.activation = activation\n",
    "        self.gaussian_noise_std = gaussian_noise_std   \n",
    "        self.encoder_layers = nn.ModuleList()\n",
    "\n",
    "        # Gaussian noise layer\n",
    "        if gaussian_noise_std:\n",
    "            self.noise_layer = GaussianNoise3D(gaussian_noise_std)\n",
    "        else:\n",
    "            self.noise_layer = None\n",
    "\n",
    "        # Convolutional layers\n",
    "        in_channels = input_shape[0]\n",
    "        for i in range(network_depth):\n",
    "            for j in range(no_convolutions):\n",
    "                out_channels = self.conv_filter_no_init * (2 ** i)\n",
    "                conv_layer = nn.Conv3d(in_channels, out_channels, conv_kernel_size, padding=conv_kernel_size // 2)\n",
    "                self.encoder_layers.append(conv_layer)\n",
    "                if self.use_batch_normalization:\n",
    "                    self.encoder_layers.append(nn.BatchNorm3d(out_channels))\n",
    "                if self.activation == 'leakyrelu':\n",
    "                    self.encoder_layers.append(nn.LeakyReLU(inplace=True))\n",
    "                else:\n",
    "                    self.encoder_layers.append(nn.ReLU(inplace=True))\n",
    "                in_channels = out_channels\n",
    "            self.encoder_layers.append(nn.MaxPool3d(kernel_size=2, stride=2))\n",
    "            if dropout_value:\n",
    "                self.encoder_layers.append(nn.Dropout3d(p=dropout_value))\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Calculate feature map size after convolution\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, *input_shape)\n",
    "            conv_output = self._forward_conv_layers(dummy_input)\n",
    "            self.feature_map_size = conv_output.size()\n",
    "            flattened_dim = conv_output.view(1, -1).size(1)\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(flattened_dim, latent_representation_dim)\n",
    "        if activation == 'leakyrelu':\n",
    "            self.activation_fn = nn.LeakyReLU(inplace=True)\n",
    "        else:\n",
    "            self.activation_fn = nn.ReLU(inplace=True)\n",
    "            \n",
    "    def _forward_conv_layers(self, x):\n",
    "        if self.noise_layer:\n",
    "            x = self.noise_layer(x)\n",
    "        for layer in self.encoder_layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self._forward_conv_layers(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.activation_fn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## hyperparameter tuning\n",
    "\n",
    "from ray import tune\n",
    "from ray import train\n",
    "from ray.train import Checkpoint, get_checkpoint\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "import ray.cloudpickle as pickle\n",
    "from ray.tune import CLIReporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_fn(depth):\n",
    "    if depth == 4:\n",
    "        return [(2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2)]  # Increase depth upsample factor to 2\n",
    "    elif depth == 2:\n",
    "        return [(4, 4, 4), (4, 4, 4)]  # Increase depth upsample factor to 4 if needed\n",
    "    else:\n",
    "        raise ValueError(f'Unsupported depth: {depth}')\n",
    "    \n",
    "class Decoder3D(nn.Module):\n",
    "    def __init__(self, conv_shape, network_depth, no_convolutions, conv_filter_no_init,\n",
    "                 conv_kernel_size, latent_representation_dim, output_channels=5, l1=0.0, l2=0.0,\n",
    "                 dropout_value=0.0, use_batch_normalization=False, activation='relu'):\n",
    "        super(Decoder3D, self).__init__()\n",
    "        self.conv_shape = conv_shape  # Shape of the feature map at the start of the decoder\n",
    "        self.network_depth = network_depth\n",
    "        self.no_convolutions = no_convolutions\n",
    "        self.conv_filter_no_init = conv_filter_no_init\n",
    "        self.conv_kernel_size = conv_kernel_size\n",
    "        self.latent_representation_dim = latent_representation_dim\n",
    "        self.l1 = l1\n",
    "        self.l2 = l2\n",
    "        self.dropout_value = dropout_value\n",
    "        self.use_batch_normalization = use_batch_normalization\n",
    "        self.activation = activation\n",
    "        self.output_channels = output_channels  # Final output channels (e.g., 5 channels for MRI modalities)\n",
    "        \n",
    "        # Activation function\n",
    "        if activation == 'leakyrelu':\n",
    "            self.activation_fn = nn.LeakyReLU(inplace=True)\n",
    "        else:\n",
    "            self.activation_fn = nn.ReLU(inplace=True)\n",
    "\n",
    "        # Fully connected layer to reshape the latent vector into a 3D shape\n",
    "        self.fc = nn.Linear(latent_representation_dim, np.prod(self.conv_shape))\n",
    "\n",
    "        # Reshape layer to convert the flat output of the FC layer into a 3D volume\n",
    "        self.reshape = lambda x: x.view(-1, *self.conv_shape)\n",
    "        \n",
    "        # Decoder layers (upsample and conv layers)\n",
    "        self.decoder_layers = nn.ModuleList()\n",
    "        \n",
    "        # Reverse the depth, so we progressively upsample back to the original image size\n",
    "        in_channels = conv_shape[0]  # Start with the number of channels from the conv_shape\n",
    "        for i in reversed(range(network_depth)):\n",
    "            # Upsampling layer\n",
    "            upsample_factors = downsample_fn(network_depth)[i]\n",
    "            self.decoder_layers.append(nn.Upsample(scale_factor=upsample_factors, mode='trilinear', align_corners=False))\n",
    "            \n",
    "            # Convolution layers\n",
    "            out_channels = self.conv_filter_no_init * (2 ** i)  # Reduce the number of channels as we move up the network\n",
    "            for j in range(no_convolutions):\n",
    "                print(f\"Layer {i}-{j}: in_channels = {in_channels}, out_channels = {out_channels}\")\n",
    "                self.decoder_layers.append(nn.Conv3d(in_channels, out_channels, kernel_size=conv_kernel_size, padding=1))\n",
    "                if use_batch_normalization:\n",
    "                    self.decoder_layers.append(nn.BatchNorm3d(out_channels))\n",
    "                if activation == 'leakyrelu':\n",
    "                    self.decoder_layers.append(nn.LeakyReLU(inplace=True))\n",
    "                else:\n",
    "                    self.decoder_layers.append(nn.ReLU(inplace=True))\n",
    "                in_channels = out_channels  # Update in_channels for the next layer\n",
    "            if dropout_value > 0.0:\n",
    "                self.decoder_layers.append(nn.Dropout3d(p=dropout_value))\n",
    "        \n",
    "        # Final convolution to produce the reconstructed image with the correct number of output channels\n",
    "        print(f\"Final Layer: in_channels = {in_channels}, out_channels = {self.output_channels}\")\n",
    "        self.final_conv = nn.Conv3d(in_channels, self.output_channels, conv_kernel_size, padding=1)\n",
    "        self.final_activation = nn.ReLU()  # You could change this to `nn.Sigmoid()` or `nn.Tanh()` depending on the data range\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Expand the latent vector via the fully connected layer\n",
    "        x = self.fc(x)\n",
    "        x = self.activation_fn(x)\n",
    "        \n",
    "        # Reshape to the shape required for the convolutional layers\n",
    "        x = self.reshape(x)  # Reshape to 3D tensor (batch_size, channels, depth, height, width)\n",
    "        \n",
    "        # Apply the decoder layers\n",
    "        for layer in self.decoder_layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        # Final convolution to produce the output volume\n",
    "        x = self.final_conv(x)\n",
    "        x = self.final_activation(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatentParametersModel(nn.Module):\n",
    "    def __init__(self, latent_representation_dim, l1=0.0, l2=0.0):\n",
    "        super(LatentParametersModel, self).__init__()\n",
    "        self.mu_sigma_layer = nn.Linear(\n",
    "            in_features=latent_representation_dim, \n",
    "            out_features=2\n",
    "        )\n",
    "        nn.init.xavier_uniform_(self.mu_sigma_layer.weight)\n",
    "        nn.init.zeros_(self.mu_sigma_layer.bias)\n",
    "        self.l1 = l1\n",
    "        self.l2 = l2\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu_sigma = self.mu_sigma_layer(x)\n",
    "        return mu_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruction_loss(y_true, y_pred):\n",
    "    mse_loss = F.mse_loss(y_pred, y_true, reduction='none')\n",
    "    reduced_loss = mse_loss.mean(dim=[1, 2, 3])\n",
    "    return reduced_loss\n",
    "\n",
    "def survival_loss(mu, sigma, x, delta):\n",
    "    \"\"\"\n",
    "    Custom loss function based on the negative log-likelihood.\n",
    "\n",
    "    :param mu: Predicted mean (log of hazard ratio), tensor of shape (batch_size,)\n",
    "    :param sigma: Predicted standard deviation (scale parameter), tensor of shape (batch_size,)\n",
    "    :param x: Observed time (log-transformed), tensor of shape (batch_size,)\n",
    "    :param delta: Event indicator (1 if event occurred, 0 if censored), tensor of shape (batch_size,)\n",
    "    :return: Computed loss, scalar value\n",
    "    \"\"\"\n",
    "    # Negative log-likelihood term\n",
    "    total_loss = -(torch.log(x)-mu)/sigma.sum()+(delta * torch.log(sigma) + (1 + delta) * torch.log(1 + torch.exp((torch.log(x)-mu)/sigma)))\n",
    "    \n",
    "    # Return the mean loss across the batch\n",
    "    return total_loss / x.size(0)\n",
    "\n",
    "# # # Example usage\n",
    "# mu = torch.tensor([0.5, 0.8, 0.3])  # Predicted means (log hazard ratios)\n",
    "# sigma = torch.tensor([1.1, 1.2, 1.1])  # Predicted standard deviations (not log-transformed)\n",
    "# x = torch.tensor([1.0, 0.8, 0.9])  # Log-transformed observed times\n",
    "# delta = torch.tensor([1.0, 0.0, 1.0])  # Event indicators\n",
    "\n",
    "# loss = survival_loss(mu, sigma, x, delta)\n",
    "# print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up hyperparameter grid for Encoder \n",
    "\n",
    "# input_shape = (5, 128, 128, 128)  # 5 channels, 240x240x155 spatial dimensions\n",
    "# conv_shape = (256, 8, 8, 8)\n",
    "\n",
    "#network_depth = 1 #4\n",
    "#no_convolutions = 1 #2\n",
    "#conv_filter_no_init = 2 #32\n",
    "#conv_kernel_size = 5 #3\n",
    "#latent_representation_dim = 8 #128\n",
    "#l1 = 0.01\n",
    "#l2 = 0.01\n",
    "#dropout_value = 0.5\n",
    "#use_batch_normalization = True\n",
    "#activation = 'leakyrelu'\n",
    "#gaussian_noise_std = 0.1\n",
    "\n",
    "config = { #lr? batchsize? \n",
    "    \"network_depth\": tune.choice([1, 2]),\n",
    "    \"no_convolutions\": tune.choice([1]),\n",
    "\n",
    "    \"conv_filter_no_init\": tune.choice([2]),\n",
    "    \"conv_kernel_size\": tune.choice([5]),\n",
    "    \"latent_representation_dim\": tune.choice([8]),\n",
    "    \n",
    "    \"l1\": tune.choice([0.001]),\n",
    "    \"l2\": tune.choice([0.001]),\n",
    "\n",
    "    \"dropout_value\": tune.choice([0.5]),\n",
    "    \"use_batch_normalization\": tune.choice([True]), \n",
    "    \"activation\": tune.choice(['leaky_relu']), #'relu', 'tanh', 'sigmoid', \n",
    "    #\"output_channels\": tune.choice([2]), #? \n",
    "    \"gaussian_noise_std\": tune.choice([0.1]),\n",
    "}\n",
    "\n",
    "### example\n",
    "# encoder = encoder(\n",
    "#     input_shape=input_shape,\n",
    "#     network_depth=network_depth,\n",
    "#     no_convolutions=no_convolutions,\n",
    "#     conv_filter_no_init=conv_filter_no_init,\n",
    "#     conv_kernel_size=conv_kernel_size,\n",
    "#     latent_representation_dim=latent_representation_dim,\n",
    "#     l1=l1,\n",
    "#     l2=l2,\n",
    "#     dropout_value=dropout_value,\n",
    "#     use_batch_normalization=use_batch_normalization,\n",
    "#     activation=activation,\n",
    "#     gaussian_noise_std=gaussian_noise_std\n",
    "# )\n",
    "\n",
    "# print(encoder.feature_map_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config, dataloader=None): # remove decoder later\n",
    "\n",
    "    ## define encoder\n",
    "    encoder = Encoder(\n",
    "        input_shape=(5, 128, 128, 128),\n",
    "        network_depth=config[\"network_depth\"],\n",
    "        no_convolutions=config[\"no_convolutions\"],\n",
    "        conv_filter_no_init=config[\"conv_filter_no_init\"],\n",
    "        conv_kernel_size=config[\"conv_kernel_size\"],\n",
    "        latent_representation_dim=config[\"latent_representation_dim\"],\n",
    "        l1=config[\"l1\"],\n",
    "        l2=config[\"l2\"],\n",
    "        dropout_value=config[\"dropout_value\"],\n",
    "        use_batch_normalization=config[\"use_batch_normalization\"],\n",
    "        activation=config[\"activation\"],\n",
    "        gaussian_noise_std=config[\"gaussian_noise_std\"]\n",
    "    )\n",
    "    print(encoder.feature_map_size)\n",
    "\n",
    "    ## define decoder \n",
    "    latent_vector = torch.randn(1, 128)  # Latent vector of size [batch_size, latent_representation_dim]\n",
    "    conv_shape = (256, 8, 8, 8)  # Example shape of the feature map before the decoder\n",
    "    decoder_model = Decoder3D(conv_shape=conv_shape, network_depth=4, no_convolutions=2, \n",
    "                            conv_filter_no_init=64, conv_kernel_size=3, \n",
    "                            latent_representation_dim=128)\n",
    "\n",
    "    # output_image = decoder_model(latent_vector)\n",
    "    # print(\"Decoder output shape:\", output_image.shape)  # Should be [batch_size, 5, 240, 240, 150] or similar\n",
    "\n",
    "    optimizer = optim.SGD(encoder.parameters(), lr=0.01, momentum=0.9)\n",
    "    encoder.train()\n",
    "    decoder_model.train()\n",
    "    device = \"cpu\" # TODO - \n",
    "    encoder.to(device)\n",
    "    decoder_model.to(device)\n",
    "\n",
    "    for epoch in range(2):\n",
    "\n",
    "        total_loss = 0\n",
    "        print(\"*********\")\n",
    "        \n",
    "        for batch in dataloader:\n",
    "            inputs, targets = batch\n",
    "\n",
    "            inputs = inputs.squeeze(2)  # Removes the dimension at index 2\n",
    "\n",
    "            # Forward pass through encoder\n",
    "            encoded = encoder(inputs)\n",
    "\n",
    "            # Generate prediction from latent dimension\n",
    "            model = LatentParametersModel(latent_representation_dim=latent_representation_dim)\n",
    "            mu_sigma = model(encoded)\n",
    "            mu = mu_sigma[0,0]\n",
    "            sigma = mu_sigma[0,1]\n",
    "\n",
    "            # Calculate loss\n",
    "            delta = torch.tensor([1.0])  #TODO - not defined?\n",
    "\n",
    "            loss = survival_loss(mu, sigma, targets, delta)\n",
    "\n",
    "            print(\"~~~~~\")\n",
    "            print(\"the current loss is: \")\n",
    "            print(loss.item())\n",
    "\n",
    "            if torch.isnan(loss).any():\n",
    "                # TODO - \n",
    "                continue\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Decoder\n",
    "\n",
    "            # Backpropagation and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        average_loss = total_loss / len(dataloader)\n",
    "        print(\"epoch\", epoch)\n",
    "        print(\"average loss is:\", average_loss)\n",
    "\n",
    "    print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a scheduler\n",
    "scheduler = ASHAScheduler(\n",
    "    metric=\"loss\",\n",
    "    mode=\"min\",\n",
    "    max_t=10,\n",
    "    grace_period=1,\n",
    "    reduction_factor=2\n",
    ")\n",
    "\n",
    "# Define a progress reporter\n",
    "reporter = CLIReporter(\n",
    "    metric_columns=[\"loss\", \"training_iteration\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-19 15:38:30,441\tINFO worker.py:1781 -- Started a local Ray instance.\n",
      "2024-08-19 15:38:30,980\tINFO tune.py:253 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run(...)`.\n",
      "2024-08-19 15:38:30,981\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-08-19 15:44:26</td></tr>\n",
       "<tr><td>Running for: </td><td>00:05:55.35        </td></tr>\n",
       "<tr><td>Memory:      </td><td>6.7/8.0 GiB        </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None<br>Logical resource usage: 4.0/8 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc           </th><th>activation  </th><th style=\"text-align: right;\">  conv_filter_no_init</th><th style=\"text-align: right;\">  conv_kernel_size</th><th style=\"text-align: right;\">  dropout_value</th><th style=\"text-align: right;\">  gaussian_noise_std</th><th style=\"text-align: right;\">   l1</th><th style=\"text-align: right;\">   l2</th><th style=\"text-align: right;\">  latent_representatio\n",
       "n_dim</th><th style=\"text-align: right;\">  network_depth</th><th style=\"text-align: right;\">  no_convolutions</th><th>use_batch_normalizat\n",
       "ion     </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_9d429_00000</td><td>RUNNING </td><td>127.0.0.1:1142</td><td>leaky_relu  </td><td style=\"text-align: right;\">                    2</td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">            0.5</td><td style=\"text-align: right;\">                 0.1</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">8</td><td style=\"text-align: right;\">              1</td><td style=\"text-align: right;\">                1</td><td>True</td></tr>\n",
       "<tr><td>train_9d429_00001</td><td>RUNNING </td><td>127.0.0.1:1143</td><td>leaky_relu  </td><td style=\"text-align: right;\">                    2</td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">            0.5</td><td style=\"text-align: right;\">                 0.1</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">8</td><td style=\"text-align: right;\">              1</td><td style=\"text-align: right;\">                1</td><td>True</td></tr>\n",
       "<tr><td>train_9d429_00002</td><td>RUNNING </td><td>127.0.0.1:1144</td><td>leaky_relu  </td><td style=\"text-align: right;\">                    2</td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">            0.5</td><td style=\"text-align: right;\">                 0.1</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">8</td><td style=\"text-align: right;\">              2</td><td style=\"text-align: right;\">                1</td><td>True</td></tr>\n",
       "<tr><td>train_9d429_00003</td><td>RUNNING </td><td>127.0.0.1:1145</td><td>leaky_relu  </td><td style=\"text-align: right;\">                    2</td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">            0.5</td><td style=\"text-align: right;\">                 0.1</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">8</td><td style=\"text-align: right;\">              2</td><td style=\"text-align: right;\">                1</td><td>True</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=1142)\u001b[0m torch.Size([1, 2, 64, 64, 64])\n",
      "\u001b[36m(func pid=1142)\u001b[0m Layer 3-0: in_channels = 256, out_channels = 512\n",
      "\u001b[36m(func pid=1142)\u001b[0m Layer 3-1: in_channels = 512, out_channels = 512\n",
      "\u001b[36m(func pid=1142)\u001b[0m Layer 2-0: in_channels = 512, out_channels = 256\n",
      "\u001b[36m(func pid=1142)\u001b[0m Layer 2-1: in_channels = 256, out_channels = 256\n",
      "\u001b[36m(func pid=1144)\u001b[0m torch.Size([1, 4, 32, 32, 32])\n",
      "\u001b[36m(func pid=1142)\u001b[0m Final Layer: in_channels = 64, out_channels = 5\n",
      "\u001b[36m(func pid=1145)\u001b[0m torch.Size([1, 4, 32, 32, 32])\n",
      "\u001b[36m(func pid=1143)\u001b[0m torch.Size([1, 2, 64, 64, 64])\n",
      "\u001b[36m(func pid=1142)\u001b[0m *********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-19 15:42:00,156\tWARNING util.py:201 -- The `on_step_begin` operation took 1.942 s, which may be a performance bottleneck.\n",
      "2024-08-19 15:42:12,773\tWARNING util.py:201 -- The `choose_trial_to_run` operation took 0.925 s, which may be a performance bottleneck.\n",
      "2024-08-19 15:44:25,919\tWARNING tune.py:219 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2024-08-19 15:44:26,356\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/Users/lindatang/ray_results/train_2024-08-19_15-38-30' in 0.3969s.\n",
      "2024-08-19 15:44:36,781\tINFO tune.py:1041 -- Total run time: 365.80 seconds (354.95 seconds for the tuning loop).\n",
      "2024-08-19 15:44:36,791\tWARNING tune.py:1056 -- Experiment has been interrupted, but the most recent state was saved.\n",
      "Resume experiment with: tune.run(..., resume=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(func pid=1145)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 20 leaked semaphore objects to clean up at shutdown\n",
      "\u001b[36m(func pid=1145)\u001b[0m   warnings.warn('resource_tracker: There appear to be %d '\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "# set up encoder like this \n",
    "scheduler = ASHAScheduler(\n",
    "      metric=\"loss\",\n",
    "      mode=\"min\",\n",
    "      max_t=10,\n",
    "      grace_period=1,\n",
    "      reduction_factor=2\n",
    "  )\n",
    "\n",
    "analysis = tune.run(\n",
    "      #tune.with_parameters(train, dataloader=dataloader),  # Pass your dataloader\n",
    "      partial(train, dataloader=dataloader),  # Pass your dataloader\n",
    "      resources_per_trial={\"cpu\": 1, \"gpu\": 0},\n",
    "      config=config,\n",
    "      num_samples=2,  # Number of samples from the search space\n",
    "      scheduler=scheduler, \n",
    "      resume=True\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
